{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple and effective text clustering\n",
    "\n",
    "### Input: list of documents:\n",
    " - HLV Park Hang Seo nói gì sau chiến thắng tưng bừng trước Pakistan?\n",
    " - HLV Park Hang-seo 'mất niềm tin', tiết lộ về 2 pha hỏng ăn penalty liên tiếp của Công Phượng\n",
    " - Xả súng kinh hoàng tại Điện Biên khiến 2 vợ chồng tử vong\n",
    " - Nghi án nổ súng ở Điện Biên, hai vợ chồng tử vong tại chỗ\n",
    " - Sập cầu ở Ý, 35 người thiệt mạng\n",
    " - Công Phượng đá hỏng 2 quả penalty, bố mẹ ở nhà nghĩ gì?\n",
    "     \n",
    "     \n",
    "### Output: list of clusters:\n",
    " - Cluster 1:\n",
    "     - HLV Park Hang Seo nói gì sau chiến thắng tưng bừng trước Pakistan?\n",
    "     - HLV Park Hang-seo 'mất niềm tin', tiết lộ về 2 pha hỏng ăn penalty liên tiếp của Công Phượng\n",
    " - Cluster 2:\n",
    "      - Xả súng kinh hoàng tại Điện Biên khiến 2 vợ chồng tử vong\n",
    "      - Nghi án nổ súng ở Điện Biên, hai vợ chồng tử vong tại chỗ\n",
    " - Noises:\n",
    "      - Sập cầu ở Ý, 35 người thiệt mạng\n",
    " \n",
    "### Approach: connected components Clustering\n",
    "\n",
    "<img src=\"Example.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:  91\n",
      "Làm tình trên ghế Sweetbox: Khi sự riêng tư đi quá giới hạn\n",
      "Khán giả bỏ tiền để tận hưởng không gian riêng tư, không bị làm phiền do 'chiếc hộp ngọt ngào' tạo ra giữa rạp chiếu phim. Nhưng đó thực tế vẫn là chốn công cộng.\n",
      "\n",
      "Link xem trực tiếp U16 Việt Nam vs U16 Philippines\n",
      "Dân Việt xin gửi tới quý độc giả link xem trực tiếp U16 Việt Nam vs U16 Philippines trong khuôn khổ lượt trận thứ 4 bảng A vòng bảng giải U16 Đông Nam Á 2018. Đây là trận đấu mà U16 Việt Nam cần thắng để tiếp tục nuôi hy vọng giành vé vào bán kết.\n",
      "\n",
      "Lộ diện thông số kỹ thuật đặc biệt Galaxy Note 9\n",
      "thegioitiepthi.vn Galaxy Note 9 sẽ ra mắt trong vài ngày tới. Mới đây một hộp bán lẻ thiết bị nghi là của Galaxy Note 9 tại Nga đã bị rò rỉ, lộ thông sồ kỹ thuật đặc biệt có ở chiếc điện thoại này.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "documents = []\n",
    "for doc in os.listdir('documents/'):\n",
    "    with open('documents/' + doc) as f:\n",
    "        documents.append(f.read().decode('utf-8'))\n",
    "        \n",
    "print \"Number of documents: \", len(documents)\n",
    "for i in range(0,3):\n",
    "    print documents[i] + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tình ghế sweetbox tư đi giới hạn khán giả tiền tận hưởng gian tư phiền 'chiếc hộp ngào rạp chiếu phim thực tế chốn công cộng .làm_tình ghế_sweetbox tư_đi giới_hạn hạn_khán khán_giả tận_hưởng 'chiếc_hộp rạp_chiếu chiếu_phim thực_tế chốn_công công_cộng\n",
      "\n",
      "link trực tiếp u16 việt nam vs u16 philippines dân việt gửi quý độc giả link trực tiếp u16 việt nam vs u16 philippines khuôn khổ lượt trận bảng a vòng bảng giải u16 đông nam trận đấu u16 việt nam thắng tiếp tục nuôi hy vọng giành vé kết trực_tiếp tiếp_u16 u16_việt việt_nam nam_vs vs_u16 u16_philippines philippines_dân dân_việt quý_độc độc_giả giả_link trực_tiếp tiếp_u16 u16_việt việt_nam nam_vs vs_u16 u16_philippines khuôn_khổ khổ_lượt lượt_trận bảng_a a_vòng vòng_bảng bảng_giải giải_u16 u16_đông đông_nam trận_đấu u16_việt việt_nam tiếp_tục tục_nuôi nuôi_hy hy_vọng vọng_giành giành_vé\n",
      "\n",
      "lộ diện thông kỹ thuật đặc biệt galaxy note thegioitiepthi.vn galaxy note mắt hộp lẻ thiết nghi galaxy note nga rò rỉ lộ thông sồ kỹ thuật đặc biệt điện thoại .lộ_diện diện_thông kỹ_thuật thuật_đặc đặc_biệt biệt_galaxy galaxy_note thegioitiepthi.vn_galaxy galaxy_note lẻ_thiết galaxy_note rò_rỉ lộ_thông thông_sồ sồ_kỹ kỹ_thuật thuật_đặc đặc_biệt điện_thoại\n",
      "\n",
      "lào cai tra vụ án giết phường nam cường 2/8 thông lãnh đạo ubnd phường nam cường tp lào cai xác địa bàn xảy vụ án mạng nghiêm trọng phụ nữ tử vong .lào_cai tra_vụ vụ_án án_giết phường_nam nam_cường lãnh_đạo đạo_ubnd ubnd_phường phường_nam nam_cường tp_lào lào_cai địa_bàn vụ_án án_mạng mạng_nghiêm nghiêm_trọng phụ_nữ nữ_tử tử_vong\n",
      "\n",
      "cgv nhân viên phát tán cảnh nóng hàng cgv quyết định chấm dứt hợp đồng lao động thức buộc nhân viên phát tán cảnh nóng hàng mạng xã hội nhân_viên viên_phát phát_tán tán_cảnh cảnh_nóng hàng_cgv cgv_quyết quyết_định định_chấm chấm_dứt dứt_hợp hợp_đồng đồng_lao lao_động thức_buộc nhân_viên viên_phát phát_tán tán_cảnh cảnh_nóng mạng_xã xã_hội\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from multiprocessing import Pool\n",
    "\n",
    "stopwords = set(open('stopwords.txt').read().decode('utf-8').split('\\n')[:-1])\n",
    "puct_set = set([c for c in '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^`{|}~'])\n",
    "\n",
    "def generateBigram(paper):\n",
    "    words = paper.split()\n",
    "    if len(words) == 1:\n",
    "        return ''\n",
    "    bigrams = [words[i] + '_' + words[i+1] for i in range(0,len(words) - 1)]\n",
    "    return ' '.join(bigrams)\n",
    "\n",
    "def removeRedundant(text,redundantSet):\n",
    "    words = text.split()\n",
    "    for i in range(0,len(words)):\n",
    "        if words[i].count('_') == 0 and (words[i] in redundantSet or words[i].isdigit()):\n",
    "            words[i] = ''\n",
    "        else:\n",
    "            sub_words = words[i].split('_')\n",
    "            if any(w in redundantSet or w.isdigit() for w in sub_words):\n",
    "                words[i] = ''\n",
    "    words = [w for w in words if w != '']\n",
    "    words = ' '.join(words)\n",
    "    return words\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = ' '.join(word_tokenize(text))\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    text = text + generateBigram(text)\n",
    "    text = removeRedundant(text,puct_set | stopwords)\n",
    "    return text\n",
    "\n",
    "\n",
    "pool = Pool(10)\n",
    "clean_documents = pool.map(preprocessing,documents)\n",
    "pool.terminate()\n",
    "\n",
    "for i in range(0,5):\n",
    "    print clean_documents[i] + '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction = LSA = TruncatedSVD(TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-idf shape: (91, 592)\n",
      "Document 1's Vector : \n",
      "[ 2.46059673e-01 -6.93897695e-02 -1.21132144e-02 -7.39961047e-03\n",
      "  1.92432455e-02 -6.50538301e-03  2.06772839e-02 -7.09620156e-02\n",
      "  3.69710557e-01  1.89439544e-01  3.08607753e-01  2.17397839e-01\n",
      "  9.98025329e-02  1.90757263e-02 -8.00372763e-02  1.19205025e-01\n",
      " -4.66764179e-02  3.77910420e-02  1.40400260e-02 -2.61164433e-01\n",
      " -5.38600696e-02 -1.75021607e-01 -4.21276499e-02 -1.02424464e-01\n",
      "  6.14512775e-02 -7.38225589e-02  4.91832425e-02  2.53021881e-02\n",
      " -1.21698365e-01 -9.95706441e-02  2.95701298e-01 -1.75182609e-01\n",
      "  1.00871532e-01 -2.54352223e-01  1.61975628e-01  1.37335543e-01\n",
      " -2.91084502e-02  2.70030223e-01 -1.35844464e-01 -3.31717698e-02\n",
      " -6.12752990e-02  7.81547015e-02  1.31720563e-01  1.32475934e-02\n",
      " -4.13174037e-02 -2.07552895e-02  3.87372128e-02 -8.27967661e-02\n",
      " -5.70708451e-03 -1.08670646e-01 -3.55012434e-02 -8.94610264e-02\n",
      "  9.51899156e-02  8.66551123e-02 -7.75449694e-02 -8.00960811e-03\n",
      "  3.09602534e-03  3.48211488e-02 -7.50494897e-02  4.21491747e-02\n",
      " -6.40484513e-03 -1.41566768e-02 -5.43379063e-03 -2.38651416e-02\n",
      "  4.14373109e-03  2.34826028e-02 -2.76346578e-03  1.60655583e-02\n",
      "  2.46042188e-02 -1.66686152e-02  5.42098223e-04 -2.63253242e-02\n",
      " -1.63081438e-02  1.06823695e-02  2.93828531e-02  3.38141732e-03\n",
      " -3.05787654e-02 -1.05458299e-02 -2.40990460e-03 -1.33523837e-02\n",
      "  3.24392389e-03 -1.46857892e-02  3.18785191e-03  6.19089360e-05\n",
      " -3.82895095e-03 -5.26404663e-03  4.11734280e-04  1.10305165e-03\n",
      " -4.93316156e-03  1.15638030e-03  2.52875926e-03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(token_pattern = \"\\S+\", min_df = 2)\n",
    "vectors = vectorizer.fit_transform(clean_documents)\n",
    "\n",
    "print \"Tf-idf shape: \" + str(vectors.shape)\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=10, random_state=42)\n",
    "svd_vectors = svd.fit_transform(vectors)\n",
    "\n",
    "print \"Document 1's Vector : \"\n",
    "print svd_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate document similarity for all pair of document:\n",
    " - pairwise_distances(document1,document2)\n",
    " - pairwise_distances(document1,document3)\n",
    " - ......\n",
    " - pairwise_distances(documentN-1,documentN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine distance between Document 1 and Document 2 :  0.9663\n",
      "cosine distance between Document 2 and Document 3 :  0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "def distance(vecs):\n",
    "    vec1 = vecs[0]\n",
    "    vecAll = vecs[1]\n",
    "    Dis_matrix = pairwise_distances(vec1,vecAll,metric = 'cosine',n_jobs=1)\n",
    "    Dis_matrix = Dis_matrix.astype(np.float16)\n",
    "    return Dis_matrix\n",
    "\n",
    "def chunks_vec(l, n):\n",
    "    for i in range(0, l.shape[0], n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "vector_chunks = list(chunks_vec(svd_vectors,1000))\n",
    "vector_chunks = [(i,svd_vectors) for i in vector_chunks]\n",
    "\n",
    "pool = Pool(2)\n",
    "Dis_matrix = pool.map(distance,vector_chunks)\n",
    "Dis_matrix = np.vstack(Dis_matrix)\n",
    "pool.terminate()\n",
    "\n",
    "print 'cosine distance between Document 1 and Document 2 : ', Dis_matrix[0][2]\n",
    "print 'cosine distance between Document 2 and Document 3 : ', Dis_matrix[2][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph\n",
    " - DocumentN is connected with DocumentM only if cosine_distance(DocumentN, DocumentM) < THRESHOLD\n",
    " - THRESHOLD = 0.4 (Change this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "graph = deepcopy(Dis_matrix)\n",
    "graph[graph <= THRESHOLD] = 2\n",
    "graph[graph != 2] = 0\n",
    "graph[graph == 2] = 1\n",
    "graph = graph.astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find connected components(Clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import connected_components\n",
    "res = connected_components(graph,directed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cluster:  14\n",
      "Number of clustered documents:  69\n",
      "Number of noise documents:  22\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "cluster_labels = res[1]\n",
    "num_cluster = res[0]\n",
    "res_cluster = OrderedDict()\n",
    "\n",
    "for i in range(0,len(cluster_labels)):\n",
    "    if cluster_labels[i] in res_cluster: res_cluster[cluster_labels[i]].append(i)\n",
    "    else: res_cluster[cluster_labels[i]] = [i]\n",
    "\n",
    "res_cluster = [res_cluster[i] for i in range(0,num_cluster)]\n",
    "res_cluster = [sorted(r) for r in res_cluster if len(r) > 1]\n",
    "res_cluster.sort(key=len,reverse=True)\n",
    "\n",
    "print \"Number of cluster: \", len(res_cluster)\n",
    "print \"Number of clustered documents: \", len([j for i in res_cluster for j in i])\n",
    "print \"Number of noise documents: \", len(documents) - len([j for i in res_cluster for j in i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "CGV thôi việc nhân viên phát tán cảnh nóng của khách hàng\n",
      "Phát tán hình ảnh cặp đôi 'mây mưa', nhân viên rạp chiếu phim CGV bị cho thôi việc\n",
      "Sa thải nhân viên rạp chiếu phim phát tán cảnh 'nóng'\n",
      "Buộc thôi việc nhân viên phát tán hình ảnh cặp đôi thân mật thái quá trong rạp CGV\n",
      "Cặp đôi thân mật quá đà trong rạp CGV: Lỗi tại 'ghế tình nhân' hay ý thức người dùng?\n",
      "Có nên đặt sweetbox trong rạp chiếu phim?\n",
      "Chính thức buộc thôi việc nhân viên phát tán hình ảnh cặp đôi thân mật thái quá trong rạp chiếu phim CGV\n",
      "Diễn biến mới vụ nhân viên CGV phát tán ảnh 'nóng' của khách\n",
      "Cho thôi việc nhân viên phát tán clip cặp đôi 'mây mưa' trong rạp CGV\n",
      "Cặp đôi 'mây mưa' trong rạp CGV: Đặt biển báo, cho thôi việc nhân viên phát tán\n",
      "\n",
      "\n",
      "Cluster 1\n",
      "Quan tâm bảo vệ, phòng chống bạo lực, xâm hại trẻ em\n",
      "Mỗi năm, cả nước có khoảng 2.000 trường hợp trẻ em bị bạo lực, xâm hại\n",
      "579 đối tượng bạo lực, xâm hại tình dục trẻ em bị xử lý hình sự\n",
      "Bao nhiêu trẻ em bị bạo hành, xâm hại chưa được phát hiện?\n",
      "Cả trăm vụ trẻ em bị xâm hại tình dục bởi chính người thân\n",
      "Hội nghị trực tuyến về bảo vệ trẻ em\n",
      "Trăn trở giải pháp ngăn chặn tình trạng xâm hại, bạo lực trẻ em gia tăng\n",
      "Thủ tướng chủ trì Hội nghị toàn quốc về phòng, chống xâm hại trẻ em\n",
      "Còn bao nhiêu vụ bạo hành, xâm hại trẻ em chưa được phát hiện?\n",
      "Mỗi năm, cả nước xảy ra hơn 1.500 vụ xâm hại trẻ em\n",
      "\n",
      "\n",
      "Cluster 2\n",
      "Link xem trực tiếp U16 Việt Nam vs U16 Philippines\n",
      "Đại thắng Philippines, U16 Việt Nam vẫn nhận tin kém vui về Myanmar\n",
      "Video trực tiếp U16 Việt Nam vs U16 Philippine giải U16 Đông Nam Á\n",
      "U16 Việt Nam phải thắng Myanmar\n",
      "Hủy diệt U16 Philippines, U16 Việt Nam quyết chiến với U16 Myanmar\n",
      "Link xem trực tiếp trận đấu U16 Việt Nam vs U16 Philippines\n",
      "U16 Việt Nam hủy diệt U16 Philippines, giành lại ngôi nhì bảng A\n",
      "U16 Việt Nam hạ U16 Philippines với tỉ số của set tennis\n",
      "\n",
      "\n",
      "Cluster 3\n",
      "Lào Cai: Điều tra vụ án giết người tại phường Nam Cường\n",
      "Nóng: Đã bắt được nghi can vụ giết người ở Lào Cai\n",
      "Điều tra vụ người phụ nữ tử vong với nhiều vết thương\n",
      "Truy bắt nhanh đối tượng giết người sau một ngày gây án\n",
      "Đã bắt được nghi phạm sát hại thím để cướp 60 nghìn ở Lào Cai\n",
      "Bắt được đối tượng giết người tại phường Nam Cường\n",
      "Bắt được đối tượng cướp 60 nghìn đồng rồi giết luôn thím họ\n",
      "Điều tra vụ án giết người tại phường Nam Cường, thành phố Lào Cai\n",
      "\n",
      "\n",
      "Cluster 4\n",
      "Thổ Nhĩ Kỳ đáp trả các lệnh trừng phạt của Mỹ\n",
      "Thổ Nhĩ Kỳ sẽ trả đũa các lệnh trừng phạt của Mỹ\n",
      "Thổ Nhĩ Kỳ trừng phạt ngược bộ trưởng Mỹ, căng thẳng 2 bên leo thang\n",
      "Thổ Nhĩ Kỳ không muốn tham gia trò chơi 'tất cả cùng thua' với Mỹ\n",
      "Thổ Nhĩ Kỳ chính thức giáng đòn trừng phạt Mỹ\n",
      "Quan hệ Mỹ - Thổ Nhĩ Kỳ: Rạn nứt ngày càng lớn\n",
      "Thổ Nhĩ Kỳ tung đòn đáp trả lệnh trừng phạt của Mỹ\n",
      "Quan hệ Mỹ-Thổ Nhĩ Kỳ lại… 'dậy sóng'\n",
      "\n",
      "\n",
      "Cluster 5\n",
      "Không chỉ có Cầu Vàng, Việt Nam từng khiến thế giới phải ngạc nhiên vì những công trình kiến trúc ấn tượng khác\n",
      "Du khách thích thú 'check-in' với cây cầu hình bàn tay gây 'sốt' ở Đà Nẵng\n",
      "CNN đăng tải clip quay Cầu Vàng Đà Nẵng từ trên cao, thu hút hơn 600k lượt xem\n",
      "Báo chí quốc tế khen ngợi Cầu Vàng của Việt Nam\n",
      "Du khách nước ngoài đua nhau đăng ảnh với Cầu Vàng, Đà Nẵng\n",
      "Không chỉ có Cầu Vàng, Việt Nam từng khiến thế giới phải ngạc nhiên vì những công trình khác\n",
      "Trước cầu Vàng, công trình nào ở Việt Nam từng gây ấn tượng quốc tế?\n",
      "\n",
      "\n",
      "Cluster 6\n",
      "Bật mí về bức ảnh cầu Vàng tuyệt đẹp ở Đà Nẵng xôn xao mạng xã hội những ngày qua\n",
      "Hóa ra tác giả của bức ảnh nổi tiếng Cây cầu Vàng tại Đà Nẵng là một anh chàng đẹp trai đến từ Malaysia\n",
      "Ai là tác giả bức ảnh cầu Vàng được chia sẻ rầm rộ trên mạng xã hội?\n",
      "\n",
      "\n",
      "Cluster 7\n",
      "Mỹ và Thổ Nhĩ Kỳ tìm cách 'gỡ rối' sau vụ bắt giữ linh mục Brunson\n",
      "Hai ngoại trưởng Mỹ - Thổ bàn về bước đi chung tại Syria\n",
      "Mỹ-Thổ bất ngờ chung tay giải quyết căng thẳng 'nổi cộm'\n",
      "\n",
      "\n",
      "Cluster 8\n",
      "Bộ đôi Samsung Galaxy S9, S9 Plus giảm giá tiền triệu\n",
      "Mua Samsung Galaxy A8 Star giá 14 triệu đồng có quá đắt?\n",
      "\n",
      "\n",
      "Cluster 9\n",
      "Samsung giới thiệu bộ đôi máy tính bảng Galaxy Tab\n",
      "Đã có giá Galaxy Tab S4 cao 'ngất ngưởng'\n",
      "\n",
      "\n",
      "Cluster 10\n",
      "Một phụ nữ bị sát hại trong nhà riêng ở Lào Cai, người có nhiều vết thương\n",
      "Phát hiện người phụ nữ chết trong nhà, nghi bị sát hại\n",
      "\n",
      "\n",
      "Cluster 11\n",
      "Concept Samsung Galaxy S10 gây bất ngờ vì có tới 3 phiên bản và thiết kế màn hình kiểu mới\n",
      "Ngắm Samsung Galaxy S10 đẹp mãn nhãn, iPhone X cũng phải chào thua\n",
      "\n",
      "\n",
      "Cluster 12\n",
      "Galaxy Note 9 giá 22 triệu, bản cao cấp gần 30 triệu đồng\n",
      "Giá bán Galaxy Note9 sẽ ngang ngửa Note8 tại thị trường Hàn Quốc, khởi điểm từ 975 USD, cao nhất trên 1200 USD\n",
      "\n",
      "\n",
      "Cluster 13\n",
      "Lào Cai: Bắt giữ đối tượng sát hại thím họ, cướp 60.000 đồng\n",
      "Lào Cai: Lời khai lạnh gáy của đối tượng sát hại thím họ\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(res_cluster)):\n",
    "    print \"Cluster \" + str(i)\n",
    "    for idx in res_cluster[i]:\n",
    "        print documents[idx].split('\\n')[0]\n",
    "    print '\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
